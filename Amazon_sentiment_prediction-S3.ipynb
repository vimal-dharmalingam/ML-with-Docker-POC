{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vimald\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vimald\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vimald\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import boto3\n",
    "import pickle \n",
    "from datetime import timedelta, datetime\n",
    "import os\n",
    "import sys\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "import time\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# text cleansing libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# downloading required word clouds\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_dict={\n",
    "\n",
    "    \"result_file_location\" : \"ml/analytical-result-store\",\n",
    "    \"result_file_name\"    : \"amazon_sentiment_analysis_prediction_pynb_result.csv\",\n",
    "    \"pretrained_model_loc\" : \"ml/prediction_model/amazon_sentiment_analysis_prediction_model.pkl\",\n",
    "    \"inference_data_folder\":\"ml/prediction-data\",\n",
    "    \"inference_file_name\":\"test_data_sentiment_analysis.csv\",\n",
    "    \"s3_bucket_name\" : \"swire-datalake-dev-bucket\",\n",
    "     \"inference_file_backup_path\" : \"ml/prediction-data-backup\",\n",
    "    \"inference_file_backup_key\" : \"test_data_sentiment_analysis.csv\"\n",
    "    #\"aws_id\": \"AKIA4EEJ3XXWKQ37XN2J\",\n",
    "    #\"aws_secret_key\" :\"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\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_file(bucket_name,inference_data_key): #,aws_access_id,aws_access_key\n",
    "    \"\"\" Read the csv predcition file from s3 using boto3 client\n",
    "    \"\"\"\n",
    "    client = boto3.client('s3') #, aws_access_key_id = aws_access_id , aws_secret_access_key= aws_access_key\n",
    "\n",
    "    csv_obj = client.get_object(Bucket=bucket_name, Key=inference_data_key)\n",
    "    body = csv_obj['Body']\n",
    "    csv_string = body.read().decode('utf-8')\n",
    "\n",
    "    Raw_data = pd.read_csv(StringIO(csv_string))\n",
    "    \n",
    "    return Raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle_data(bucket_name, model_key): # ,aws_access_id,aws_access_key\n",
    "    \"\"\"\n",
    "    Get the stored pretrained model from S3 bucket\n",
    "    \"\"\"\n",
    "    client = boto3.client('s3') #, aws_access_key_id = aws_access_id, aws_secret_access_key=aws_access_key\n",
    "    response = client.get_object(Bucket=bucket_name, Key=model_key)\n",
    "    body = response['Body'].read()\n",
    "    trained_model = pickle.loads(body)\n",
    "\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleansing(Raw_data,trained_tfidf_vector): \n",
    "    \n",
    "    test_data=Raw_data.drop('Unnamed: 0',axis=1)\n",
    "    #lower case all text\n",
    "    test_data[\"reviews.text\"]=test_data[\"reviews.text\"].str.lower() \n",
    "\n",
    "    #tokenization of words\n",
    "    test_data['reviews.text'] = test_data.apply(lambda row: word_tokenize(row['reviews.text']), axis=1) \n",
    "\n",
    "    #only alphanumerical values\n",
    "    test_data[\"reviews.text\"] = test_data['reviews.text'].apply(lambda x: [item for item in x if item.isalpha()]) \n",
    "\n",
    "    #lemmatazing words\n",
    "    test_data['reviews.text'] = test_data['reviews.text'].apply(lambda x : [WordNetLemmatizer().lemmatize(y) for y in x])\n",
    "\n",
    "    #removing useless words\n",
    "    stop = stopwords.words('english')\n",
    "    test_data['reviews.text'] = test_data['reviews.text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "    test_data[\"reviews.text\"] = test_data[\"reviews.text\"].apply(lambda x: str(' '.join(x))) #joining all tokens\n",
    "    sentiment = {1: 0,\n",
    "            2: 0,\n",
    "            3: 0,\n",
    "            4: 1,\n",
    "            5: 1}\n",
    "\n",
    "    test_data[\"sentiment\"] = test_data[\"reviews.rating\"].map(sentiment)\n",
    "    vectorizer =TfidfVectorizer(max_df=0.9)\n",
    "    text = vectorizer.fit_transform(test_data[\"reviews.text\"])\n",
    "    \n",
    "    converted_vector = trained_tfidf_vector.transform(test_data[\"reviews.text\"])  \n",
    "    \n",
    "    return converted_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction (converted_vector_for_model,test_data,trained_model_rf) :\n",
    "    \n",
    "    predicted_result = trained_model_rf[0].predict(converted_vector_for_model)\n",
    "    predicted_proba = trained_model_rf[0].predict_proba(converted_vector_for_model)\n",
    "    result_df = test_data[['reviews.text']]\n",
    "    result_df['actual_rating'] = test_data['reviews.rating']\n",
    "    result_df['Prediction'] = predicted_result\n",
    "    result_df['Probability']=np.round(pd.DataFrame(predicted_proba)[1],2)\n",
    "    sentiment = {0: 'Not satisfied',\n",
    "            1: \"satisfied\"}\n",
    "\n",
    "    result_df[\"sentiment\"] = result_df[\"Prediction\"].map(sentiment)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_s3(bucket_name,result_key, raw_data): # ,aws_access_id,aws_access_key\n",
    "    csv_buffer = StringIO()\n",
    "    raw_data.to_csv(csv_buffer)\n",
    "    resource = boto3.resource('s3') # , aws_access_key_id= aws_access_id ,aws_secret_access_key=aws_access_key\n",
    "    \n",
    "    return resource.Object(bucket_name,result_key).put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_and_delete_prediction_data():\n",
    "    try:\n",
    "        #backup the prediction data\n",
    "        s3 = boto3.resource('s3')\n",
    "        copy_source = {\n",
    "                       'Bucket' : bucket_name,\n",
    "                     'Key'      : inference_data_key\n",
    "                       }\n",
    "        s3.meta.client.copy(copy_source,bucket_name,inf_backup_key)\n",
    "        # deleting the object\n",
    "        s3_client=boto3.client('s3')\n",
    "        response =s3_client.delete_object(\n",
    "                                     Bucket=bucket_name,\n",
    "                                     Key=inference_data_key\n",
    "                                            )\n",
    "    except ClientError as e:\n",
    "        error_code = e.response[\"Error\"][\"Code\"]\n",
    "        print(\"File not found : \",  e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3_conn_id = var_dict[\"s3_conn_id\"]\n",
    "result_file_location = var_dict[\"result_file_location\"]\n",
    "result_file_name    =  var_dict[\"result_file_name\"]\n",
    "pretrained_model_loc = var_dict[\"pretrained_model_loc\"]\n",
    "bucket_name = var_dict[\"s3_bucket_name\"]\n",
    "inference_data_folder = var_dict[\"inference_data_folder\"]\n",
    "inference_file_name = var_dict[\"inference_file_name\"]\n",
    "backup_path_inf_file = var_dict[\"inference_file_backup_path\"]\n",
    "backup_filename_inf = var_dict[\"inference_file_backup_key\"]\n",
    "bucket_name=var_dict['s3_bucket_name']  \n",
    "\n",
    "#aws_access_id= var_dict['aws_id']\n",
    "#aws_access_key= var_dict['aws_secret_key']\n",
    "\n",
    "inference_data_key = inference_data_folder + \"/\" + inference_file_name\n",
    "model_key = pretrained_model_loc\n",
    "result_key = result_file_location +\"/\" + result_file_name\n",
    "inf_backup_key = backup_path_inf_file + \"/\"+ backup_filename_inf\n",
    "\n",
    "trained_tfidf_vector = pd.read_pickle(r'trained_tfidf_vector.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_func ():\n",
    "    \n",
    "    Raw_data = read_csv_file(bucket_name,inference_data_key)\n",
    "    \n",
    "    trained_model_rf = load_pickle_data(bucket_name, model_key)\n",
    "    \n",
    "    converted_vector = data_cleansing(Raw_data,trained_tfidf_vector)\n",
    "    \n",
    "    result_data = make_prediction (converted_vector,Raw_data,trained_model_rf)\n",
    "    #result_df = result_data.head(10)\n",
    "    #print(result_df)\n",
    "    \n",
    "    write_to_s3(bucket_name,result_key, result_data)\n",
    "    \n",
    "    copy_and_delete_prediction_data()\n",
    "    print(\"****************Predcition Done successfully and waiting for the next file\")\n",
    "    return result_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-8ad455f8ed92>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_df['actual_rating'] = test_data['reviews.rating']\n",
      "<ipython-input-19-8ad455f8ed92>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  result_df['Prediction'] = predicted_result\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************Predcition Done successfully and waiting for the next file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews.text</th>\n",
       "      <th>actual_rating</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Probability</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I can't update Facebook and a few other apps. ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>Not satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I bought this tablet for my boyfriend and he a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.97</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bought a gift for my mom. She absolutely loved...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love the kindle and the price was excellent. I...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Amazon Tap has great sound and is responsi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.95</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7722</th>\n",
       "      <td>First purchase of an e reader. Kindle Paperwhi...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.89</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7723</th>\n",
       "      <td>Easy to set up and works great with hue lighti...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7724</th>\n",
       "      <td>Purchased for 10 and 8 yr old for xmas. They l...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7725</th>\n",
       "      <td>I purchased this on sale for about $38.Worth e...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.98</td>\n",
       "      <td>satisfied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7726</th>\n",
       "      <td>They run out of power very quickly.</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Not satisfied</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7727 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           reviews.text  actual_rating  \\\n",
       "0     I can't update Facebook and a few other apps. ...            2.0   \n",
       "1     I bought this tablet for my boyfriend and he a...            5.0   \n",
       "2     Bought a gift for my mom. She absolutely loved...            5.0   \n",
       "3     Love the kindle and the price was excellent. I...            5.0   \n",
       "4     The Amazon Tap has great sound and is responsi...            5.0   \n",
       "...                                                 ...            ...   \n",
       "7722  First purchase of an e reader. Kindle Paperwhi...            5.0   \n",
       "7723  Easy to set up and works great with hue lighti...            5.0   \n",
       "7724  Purchased for 10 and 8 yr old for xmas. They l...            5.0   \n",
       "7725  I purchased this on sale for about $38.Worth e...            5.0   \n",
       "7726                They run out of power very quickly.            2.0   \n",
       "\n",
       "      Prediction  Probability      sentiment  \n",
       "0              0         0.08  Not satisfied  \n",
       "1              1         0.97      satisfied  \n",
       "2              1         1.00      satisfied  \n",
       "3              1         1.00      satisfied  \n",
       "4              1         0.95      satisfied  \n",
       "...          ...          ...            ...  \n",
       "7722           1         0.89      satisfied  \n",
       "7723           1         1.00      satisfied  \n",
       "7724           1         1.00      satisfied  \n",
       "7725           1         0.98      satisfied  \n",
       "7726           0         0.05  Not satisfied  \n",
       "\n",
       "[7727 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_func ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def prediction():\n",
    "    \n",
    "#     try:\n",
    "#         s3 = boto3.resource('s3')\n",
    "#         s3.Object(bucket_name,inference_data_key).load()\n",
    "#         #print(time.time())\n",
    "\n",
    "#     except ClientError as e:\n",
    "#         print(\"*************Waiting for the next file to predict*********************\")\n",
    "\n",
    "#     else:\n",
    "#         # The object does exist.\n",
    "#         result_func ()\n",
    "\n",
    "# if __name__ == \"__main__\" :\n",
    "    \n",
    "#     while True:\n",
    "#         time.sleep(5)\n",
    "#         prediction()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
